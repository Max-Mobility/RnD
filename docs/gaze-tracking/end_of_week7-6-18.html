<!DOCTYPE html>
<html lang="en"><head>
  <meta charset="utf-8">
  <meta http-equiv="X-UA-Compatible" content="IE=edge">
  <meta name="viewport" content="width=device-width, initial-scale=1"><!-- Begin Jekyll SEO tag v2.5.0 -->
<title>End of Week Progress Update 7/6/18 | rnd</title>
<meta name="generator" content="Jekyll v3.7.3" />
<meta property="og:title" content="End of Week Progress Update 7/6/18" />
<meta property="og:locale" content="en_US" />
<meta name="description" content="Progress Prepared William’s computer for training iTracker ML Model Downloaded and unpacked GazeCapture data Updated Nvidia drivers and Cuda toolkit (Version 9.0) to interface with Tensorflow Created development workflow pipeline for continued development of new features (useful for iteration &amp; testing after iTracker proof of concept) Implemented additional features for iTracker Model checkpoints to halt and resume training Learning Rate Scheduler to allow for variable training rates UI tweaks to provide improved feedback on model training progress Performance improvements to avoid unecessary file I/O Beginning implementation of TensorBoard to monitor training progress Current status: Model is training on William’s Computer (Nvidia GeForce GTX 1080) with 80 subjects (50 training, 20 validation, 10 testing) Findings Model execution time is currently bottlenecked by File I/O &amp; Memory space Traditional hard drives do not have enough bandwidth to train model at reasonable speed SSD is significantly faster, but is still (likely) bottlenecking model execution speed. Additional testing is required to verify this bottleneck. Tensorflow execution speed can be improved with increased V-RAM Training and iteration will only be possible on Nvidia DGX-1 Next Steps Evaluate model performance from preliminary training on William’s computer Create visualizer to visualize the output of the model Should be able to see actual gaze direction and predicted gaze direction for a given picture Train model on DGX-1 with full dataset to fully replicate results from MIT Feed new gaze data (not included in dataset) to model and test performance Modify ML model to produce the gaze vector, rather than gaze coordinates Iterate and improve peformance" />
<meta property="og:description" content="Progress Prepared William’s computer for training iTracker ML Model Downloaded and unpacked GazeCapture data Updated Nvidia drivers and Cuda toolkit (Version 9.0) to interface with Tensorflow Created development workflow pipeline for continued development of new features (useful for iteration &amp; testing after iTracker proof of concept) Implemented additional features for iTracker Model checkpoints to halt and resume training Learning Rate Scheduler to allow for variable training rates UI tweaks to provide improved feedback on model training progress Performance improvements to avoid unecessary file I/O Beginning implementation of TensorBoard to monitor training progress Current status: Model is training on William’s Computer (Nvidia GeForce GTX 1080) with 80 subjects (50 training, 20 validation, 10 testing) Findings Model execution time is currently bottlenecked by File I/O &amp; Memory space Traditional hard drives do not have enough bandwidth to train model at reasonable speed SSD is significantly faster, but is still (likely) bottlenecking model execution speed. Additional testing is required to verify this bottleneck. Tensorflow execution speed can be improved with increased V-RAM Training and iteration will only be possible on Nvidia DGX-1 Next Steps Evaluate model performance from preliminary training on William’s computer Create visualizer to visualize the output of the model Should be able to see actual gaze direction and predicted gaze direction for a given picture Train model on DGX-1 with full dataset to fully replicate results from MIT Feed new gaze data (not included in dataset) to model and test performance Modify ML model to produce the gaze vector, rather than gaze coordinates Iterate and improve peformance" />
<meta property="og:site_name" content="rnd" />
<meta property="og:type" content="article" />
<meta property="article:published_time" content="2018-08-01T17:06:22-05:00" />
<script type="application/ld+json">
{"description":"Progress Prepared William’s computer for training iTracker ML Model Downloaded and unpacked GazeCapture data Updated Nvidia drivers and Cuda toolkit (Version 9.0) to interface with Tensorflow Created development workflow pipeline for continued development of new features (useful for iteration &amp; testing after iTracker proof of concept) Implemented additional features for iTracker Model checkpoints to halt and resume training Learning Rate Scheduler to allow for variable training rates UI tweaks to provide improved feedback on model training progress Performance improvements to avoid unecessary file I/O Beginning implementation of TensorBoard to monitor training progress Current status: Model is training on William’s Computer (Nvidia GeForce GTX 1080) with 80 subjects (50 training, 20 validation, 10 testing) Findings Model execution time is currently bottlenecked by File I/O &amp; Memory space Traditional hard drives do not have enough bandwidth to train model at reasonable speed SSD is significantly faster, but is still (likely) bottlenecking model execution speed. Additional testing is required to verify this bottleneck. Tensorflow execution speed can be improved with increased V-RAM Training and iteration will only be possible on Nvidia DGX-1 Next Steps Evaluate model performance from preliminary training on William’s computer Create visualizer to visualize the output of the model Should be able to see actual gaze direction and predicted gaze direction for a given picture Train model on DGX-1 with full dataset to fully replicate results from MIT Feed new gaze data (not included in dataset) to model and test performance Modify ML model to produce the gaze vector, rather than gaze coordinates Iterate and improve peformance","@type":"BlogPosting","url":"/RnD/gaze-tracking/end_of_week7-6-18.html","headline":"End of Week Progress Update 7/6/18","dateModified":"2018-08-01T17:06:22-05:00","datePublished":"2018-08-01T17:06:22-05:00","mainEntityOfPage":{"@type":"WebPage","@id":"/RnD/gaze-tracking/end_of_week7-6-18.html"},"@context":"http://schema.org"}</script>
<!-- End Jekyll SEO tag -->
<link rel="stylesheet" href="/RnD/assets/main.css">
  <link rel="stylesheet" href="https://maxcdn.bootstrapcdn.com/font-awesome/4.7.0/css/font-awesome.min.css"/><link type="application/atom+xml" rel="alternate" href="/RnD/feed.xml" title="rnd" /></head>
<body><header class="site-header" role="banner">

  <div class="wrapper"><a class="site-title" rel="author" href="/RnD/">rnd</a><nav class="site-nav">
        <input type="checkbox" id="nav-trigger" class="nav-trigger" />
        <label for="nav-trigger">
          <span class="menu-icon">
            <svg viewBox="0 0 18 15" width="18px" height="15px">
              <path d="M18,1.484c0,0.82-0.665,1.484-1.484,1.484H1.484C0.665,2.969,0,2.304,0,1.484l0,0C0,0.665,0.665,0,1.484,0 h15.032C17.335,0,18,0.665,18,1.484L18,1.484z M18,7.516C18,8.335,17.335,9,16.516,9H1.484C0.665,9,0,8.335,0,7.516l0,0 c0-0.82,0.665-1.484,1.484-1.484h15.032C17.335,6.031,18,6.696,18,7.516L18,7.516z M18,13.516C18,14.335,17.335,15,16.516,15H1.484 C0.665,15,0,14.335,0,13.516l0,0c0-0.82,0.665-1.483,1.484-1.483h15.032C17.335,12.031,18,12.695,18,13.516L18,13.516z"/>
            </svg>
          </span>
        </label>

        <div class="trigger"><a class="page-link" href="/RnD/documentation.html">Documentation Guide</a><a class="page-link" href="/RnD/gazebo-simulation.html">Gazebo Simulation</a><a class="page-link" href="/RnD/gaze-tracking.html">Gaze Tracking</a><a class="page-link" href="/RnD/SIM.html">Spherical ACIM</a><a class="page-link" href="/RnD/mobility-unlimited.html">Mobility Unlimited</a><a class="page-link" href="/RnD/roomba.html">Roomba</a><a class="page-link" href="/RnD/autochair.html">Autochair</a><a class="page-link" href="/RnD/openpose.html">OpenPose</a></div>
      </nav></div>
</header>
<main class="page-content" aria-label="Content">
      <div class="wrapper">
        <article class="post">

  <header class="post-header">
    <h1 class="post-title">End of Week Progress Update 7/6/18</h1>
  </header>

  <div class="post-content">
    <h1 id="progress">Progress</h1>
<ul>
  <li>Prepared William’s computer for training iTracker ML Model
    <ul>
      <li>Downloaded and unpacked GazeCapture data</li>
      <li>Updated Nvidia drivers and Cuda toolkit (Version 9.0) to interface with Tensorflow</li>
    </ul>
  </li>
  <li>Created development workflow pipeline for continued development of new features (useful for iteration &amp; testing after iTracker proof of concept)</li>
  <li>Implemented additional features for iTracker
    <ul>
      <li>Model checkpoints to halt and resume training</li>
      <li>Learning Rate Scheduler to allow for variable training rates</li>
      <li>UI tweaks to provide improved feedback on model training progress</li>
      <li>Performance improvements to avoid unecessary file I/O</li>
      <li>Beginning implementation of TensorBoard to monitor training progress</li>
    </ul>
  </li>
  <li>Current status:
    <ul>
      <li>Model is training on William’s Computer (Nvidia GeForce GTX 1080) with 80 subjects (50 training, 20 validation, 10 testing)</li>
    </ul>
  </li>
</ul>

<h1 id="findings">Findings</h1>
<ul>
  <li>Model execution time is currently bottlenecked by File I/O &amp; Memory space
    <ul>
      <li>Traditional hard drives do not have enough bandwidth to train model at reasonable speed</li>
      <li>SSD is significantly faster, but is still (likely) bottlenecking model execution speed. Additional testing is required to verify this bottleneck.</li>
      <li>Tensorflow execution speed can be improved with increased V-RAM</li>
      <li>Training and iteration will only be possible on Nvidia DGX-1</li>
    </ul>
  </li>
</ul>

<h1 id="next-steps">Next Steps</h1>
<ul>
  <li>Evaluate model performance from preliminary training on William’s computer</li>
  <li>Create visualizer to visualize the output of the model
    <ul>
      <li>Should be able to see actual gaze direction and predicted gaze direction for a given picture</li>
    </ul>
  </li>
  <li>Train model on DGX-1 with full dataset to fully replicate results from MIT</li>
  <li>Feed new gaze data (not included in dataset) to model and test performance</li>
  <li>Modify ML model to produce the gaze vector, rather than gaze coordinates</li>
  <li>Iterate and improve peformance</li>
</ul>

  </div>

</article>

      </div>
    </main><footer class="site-footer h-card">
  <data class="u-url" href="/RnD/"></data>

  <div class="wrapper">

    <h2 class="footer-heading">rnd</h2>

    <div class="footer-col-wrapper">
      <div class="footer-col footer-col-1">
        <ul class="contact-list">
          <li class="p-name">rnd</li></ul>
      </div>

      <div class="footer-col footer-col-2"><ul class="social-media-list"></ul>
</div>

      <div class="footer-col footer-col-3">
        <p>Centralized repo for R&amp;D documentation</p>
      </div>
    </div>

  </div>

</footer>
</body>

</html>
